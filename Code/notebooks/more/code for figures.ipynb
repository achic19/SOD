{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "from osmnx import io\n",
    "import glob\n",
    "\n",
    "project_crs = 'epsg:3857'\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pjr_loc = os.path.dirname(os.getcwd())\n"
   ],
   "id": "e3c291ff063cb14c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This code selects 10% of the streets randomly  to analysis manually  \n",
    "# parameters\n",
    "first_time = False\n",
    "for place in ['Tel_Aviv','San_Francisco__California','Turin_Italy']:\n",
    "    # if place!='San_Francisco__California':\n",
    "    #     continue\n",
    "    name ='name'\n",
    "\n",
    "    if first_time:\n",
    "        # Get Dataframe and choose only the simplified ones\n",
    "        df = gpd.read_file(f'places/{place}/simp.shp')\n",
    "\n",
    "\n",
    "        # Select 20% randomly\n",
    "        unique_names = df[df['is_simplif']==1]['name'].unique()\n",
    "        selected_names = pd.DataFrame(pd.Series(unique_names).sample(frac=0.1, random_state=42))\n",
    "        selected_names['is_same']=''\n",
    "        selected_names.set_index(0, inplace=True,)\n",
    "        selected_names.index.name= 'street'\n",
    "    else:\n",
    "        selected_names = pd.read_csv(f'places/{place}/selected_streets.csv').set_index('Street name')[['Status 1','Status 2']]\n",
    "\n",
    "    # Save the selected original streets in new shp files (regular and dissolve)\n",
    "    df_2 = gpd.read_file(f'places/{place}/osm_data.gpkg',layer = 'edges')\n",
    "    if place=='Tel_Aviv':\n",
    "        df_2[name] = df_2['name:en']\n",
    "        df_2.drop(columns='name:en',inplace=True)\n",
    "    res = df_2[df_2[name].isin(selected_names.index)]\n",
    "    res.to_file(f'places/{place}/selected_streets.shp')\n",
    "    res.dissolve(by=name).sort_values(by=name).to_file(f'places/{place}/selected_streets.shp')\n",
    "    # Create df to be filled in manually\n",
    "    code_to_repeat = \"selected_names.loc['',:]= []\"\n",
    "\n",
    "    # Loop to repeat the code\n",
    "    for street in selected_names.index:\n",
    "        print(f\"selected_names.loc['{street}',:]= []\")"
   ],
   "id": "5b4220ef556f7fd5",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  Data for figure 8:\n",
    "#('Tel_Aviv', 'Tel_Aviv')\n",
    "\n",
    "# ('Turin_Italy', 'Turin'),\n",
    "# ('San_Francisco__California', 'San_Francisco'),\n",
    "## Choose locations and create folders if necessary\n",
    "place = 'Turin_Italy'\n",
    "data_folder = os.path.join(pjr_loc, f'places/{place}')\n",
    "os.makedirs(f'{data_folder}/csv/', exist_ok=True)  # Here the csv files will be stored\n",
    "before_df = gpd.read_file(f'{data_folder}/before_df.shp')\n",
    "after_df = gpd.read_file(f'{data_folder}/network_new.shp').drop(columns='index')\n",
    "\n",
    "\n",
    "# step 1-4 as one def\n",
    "def street_its_connections(network, is_simplified=False):\n",
    "    \"\"\"\n",
    "    Perform a spatial join to identify all streets connected to each street in the dataset.\n",
    "    :param is_simplified:Decide whether to store the status of 'is_simplified'.\n",
    "    :param network:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # vars\n",
    "    str_name = 'name_left'\n",
    "    con_str_name = 'name_right'\n",
    "    # 1.\tCopy network\n",
    "    df_analysis = network.copy()\n",
    "    # 2.\tInternal intersection\n",
    "    s_join_analysis = gpd.sjoin(df_analysis, network)\n",
    "    # 3.\tDelete those with the same name\n",
    "\n",
    "    s_join_analysis2 = s_join_analysis[s_join_analysis[str_name] != s_join_analysis[con_str_name]]\n",
    "    # 4.\tFor each group: name: list\n",
    "    group_name = s_join_analysis2.groupby(str_name)\n",
    "    dic_data = {}\n",
    "\n",
    "    def connected_streets(str_lines):\n",
    "        \"\"\"\n",
    "        Populate the dictionary with the name of the current street and all its connected streets.\n",
    "        :param str_lines:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if is_simplified:  # after SOD process we also want to know if all/part of the street was simplified.\n",
    "            dic_data[str_lines[str_name].iloc[0]] = (\n",
    "            list(str_lines[con_str_name].unique()), True if (str_lines['is_simplif_left'] == 1).any() else False)\n",
    "        else:\n",
    "            dic_data[str_lines[str_name].iloc[0]] = (list(str_lines[con_str_name].unique()), False)\n",
    "\n",
    "    group_name.apply(connected_streets)\n",
    "    return dic_data\n",
    "\n",
    "\n",
    "# Create dictionary of street: connected streets before and after\n",
    "dic_before = street_its_connections(before_df)\n",
    "print('dic_before')\n",
    "dic_after = street_its_connections(after_df, is_simplified=True)\n",
    "print('dic_after')\n",
    "# 5. Compare between the two dictionaries\n",
    "df1 = pd.DataFrame(index=dic_after.keys(), data=dic_after.values(),\n",
    "                   columns=['ConnectedStreets', 'is_simplified']).reset_index(names='StreetName')\n",
    "df2 = pd.DataFrame(index=dic_before.keys(), data=dic_before.values(),\n",
    "                   columns=['ConnectedStreets', 'is_simplified']).reset_index(names='StreetName')\n",
    "\n",
    "\n",
    "def common_streets(row):\n",
    "    \"\"\"\n",
    "    This function compares the connected streets of a given street in the current row with those in another DataFrame (df2).\n",
    "    It returns the count of common connected streets.\n",
    "\n",
    "    Parameters:\n",
    "    row (pandas.Series): A row from the original DataFrame containing 'StreetName' and 'ConnectedStreets' columns.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of common connected streets between the given row and the corresponding street in df2.\n",
    "    \"\"\"\n",
    "    # Filter df2 to find the streets with the same name as the current row's street\n",
    "    streets_in_old = df2[df2['StreetName'] == row['StreetName']]\n",
    "\n",
    "    # Check if there are no matching streets in df2\n",
    "    if streets_in_old.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        # Calculate the intersection of connected streets between the current row and the matched street in df2\n",
    "        return len(set(row['ConnectedStreets']) & set(streets_in_old['ConnectedStreets'].iloc[0]))\n",
    "\n",
    "\n",
    "def unique_streets_in_df1(row):\n",
    "    \"\"\"\n",
    "    This function compares the connected streets of a given street in the current row with those in another DataFrame (df2).\n",
    "    It returns the count of unique connected streets that are present in the current row but not in df2.\n",
    "\n",
    "    Parameters:\n",
    "    row (pandas.Series): A row from the original DataFrame containing 'StreetName' and 'ConnectedStreets' columns.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of unique connected streets that are in the current row but not in the corresponding street in df2.\n",
    "    \"\"\"\n",
    "    # Filter df2 to find the streets with the same name as the current row's street\n",
    "    streets_in_old = df2[df2['StreetName'] == row['StreetName']]\n",
    "\n",
    "    # Check if there are no matching streets in df2\n",
    "    if streets_in_old.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        # Calculate the unique connected streets in the current row that are not in the matched street in df2\n",
    "        return len(set(row['ConnectedStreets']) - set(streets_in_old['ConnectedStreets'].iloc[0]))\n",
    "\n",
    "\n",
    "def unique_streets_in_df2(row):\n",
    "    \"\"\"\n",
    "    This function compares the connected streets of a given street in the current row with those in another DataFrame (df2).\n",
    "    It returns the count of unique connected streets that are present in df2 but not in the current row.\n",
    "\n",
    "    Parameters:\n",
    "    row (pandas.Series): A row from the original DataFrame containing 'StreetName' and 'ConnectedStreets' columns.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of unique connected streets that are in the corresponding street in df2 but not in the current row.\n",
    "    \"\"\"\n",
    "    # Filter df2 to find the streets with the same name as the current row's street\n",
    "    streets_in_old = df2[df2['StreetName'] == row['StreetName']]\n",
    "\n",
    "    # Check if there are no matching streets in df2\n",
    "    if streets_in_old.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        # Calculate the unique connected streets in the matched street in df2 that are not in the current row\n",
    "        return len(set(streets_in_old['ConnectedStreets'].iloc[0]) - set(row['ConnectedStreets']))\n",
    "\n",
    "\n",
    "df1['CommonStreetsCount'] = df1.apply(common_streets, axis=1)\n",
    "df1['UniqueStreetsInAfterCount'] = df1.apply(unique_streets_in_df1, axis=1)\n",
    "df1['UniqueStreetsInBeforeCount'] = df1.apply(unique_streets_in_df2, axis=1)\n",
    "\n",
    "df1['rate_success'] = (df1['CommonStreetsCount'] / df1[\n",
    "    ['CommonStreetsCount', 'UniqueStreetsInAfterCount', 'UniqueStreetsInBeforeCount']].sum(axis=1) * 100).round(0)\n",
    "\n",
    "# Calculate rate success\n",
    "df1['rate_success'] = (df1['CommonStreetsCount'] / df1[\n",
    "    ['CommonStreetsCount', 'UniqueStreetsInAfterCount', 'UniqueStreetsInBeforeCount']].sum(axis=1) * 100).round(0)\n",
    "\n",
    "# Update the original data source\n",
    "after_df2 = after_df.set_index('name')\n",
    "after_df2['rate_success'] = df1.set_index('StreetName')['rate_success']\n",
    "after_df2 = after_df2.reset_index().dissolve(by='name')\n",
    "after_df2.to_file(f'{data_folder}/after_df.shp')\n",
    "df1.to_csv(f'{data_folder}/csv/after_df.csv')\n",
    "df2.to_csv(f'{data_folder}/csv/before_df.csv')\n",
    "rate_success = 'rate_success'\n",
    "is_simplified = 'is_simplified'\n",
    "print(f'mean: {df1[rate_success].mean()}')\n",
    "print(f'mean_simplified: {df1[df1[is_simplified]][rate_success].mean()}')\n",
    "print(f'mean_no_simplified: {df1[~df1[is_simplified]][rate_success].mean()}')"
   ],
   "id": "72c37471a6e8697b",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
