{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T06:25:48.873928Z",
     "start_time": "2024-07-17T06:25:48.755143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import os\n",
    "\n",
    "project_crs = 'epsg:3857'\n",
    "\n",
    "place ='Turin_Italy'\n",
    "pjr_loc = os.path.dirname(os.getcwd())\n",
    "data_folder= os.path.join(pjr_loc, f'places/{place}')\n",
    "test_data_folder = os.path.join(data_folder, 'test/Aggregation')\n",
    "\n",
    "# if you want to save the files\n",
    "def save_points_file(data, path):\n",
    "    \"\"\"\n",
    "    The function get a data, arrange columns, convert list to string and export  it into a shpfile\n",
    "    :param data:\n",
    "    :param path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    col_of_lists_as_str = 'col_of_lists_as_str'\n",
    "    data[col_of_lists_as_str] = data[index_right].apply(str)\n",
    "    data.drop(columns=[index_right]).to_file(path)\n",
    "    data.drop(columns=[col_of_lists_as_str], inplace=True)"
   ],
   "id": "b455c5742a2a6268",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "61e3053e83e37878",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T06:10:08.912439Z",
     "start_time": "2024-07-17T06:10:04.821246Z"
    }
   },
   "source": [
    "# Aggregation\n",
    "print('Aggregate intersections')\n",
    "network= gpd.read_file(f'{data_folder}/network.shp')\n",
    "\n",
    "\n",
    "# 1. Get the first/start of each line\n",
    "# Extract unique start and end points from all LineStrings\n",
    "geometry = 'geometry'\n",
    "index_right = 'index_right'\n",
    "all_points = network[geometry].apply(lambda line: [Point(line.coords[0]), Point(line.coords[-1])]).explode()\n",
    "# # Create a GeoSeries of unique points\n",
    "unique_points = GeoDataFrame(geometry=gpd.GeoSeries(all_points).unique(), crs=project_crs)\n",
    "# save data\n",
    "unique_points.to_file(f'{test_data_folder}/unique_points.shp')"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T06:13:08.105538Z",
     "start_time": "2024-07-17T06:13:03.229654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Make sure I have the name of the lines associated with these lines\n",
    "pnts_line_name = unique_points.sjoin(network)[[index_right, geometry]].reset_index().dissolve(by='index',\n",
    "                                                                                              aggfunc=lambda\n",
    "                                                                                                  x: x.tolist())\n",
    "pnts_line_name['num_of_lines'] = pnts_line_name[index_right].apply(len) \n",
    "save_points_file(pnts_line_name, f'{test_data_folder}/pnts_line_name.shp')# count the number of lines for each point"
   ],
   "id": "912cdd952dfa73a",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "\n",
    "\n",
    "# 3. Use DBSCAN with 20 meters threshold\n",
    "# Extract coordinates for DBSCAN\n",
    "coordinates = pnts_line_name.geometry.apply(lambda point: (point.x, point.y)).tolist()\n",
    "dbscan = DBSCAN(eps=40, min_samples=2)\n",
    "pnts_line_name['group'] = dbscan.fit_predict(coordinates)\n",
    "lines_to_update = pnts_line_name[pnts_line_name['group'] > -1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4.1.Find the point with the max number of connected lines, if it is one use it otherwise uses the average\n",
    "# Find the maximum 'num' value for each group\n",
    "num = 'num_of_lines'\n",
    "group_name = 'group'\n",
    "new_geometry = 'new_geometry'\n",
    "max_values_per_group = lines_to_update.groupby('group')['num_of_lines'].max()\n",
    "# Filter rows with the maximum 'num' value for each group\n",
    "result_gdf = lines_to_update[\n",
    "    lines_to_update.set_index([group_name, num]).index.isin(list(max_values_per_group.items()))]\n",
    "\n",
    "\n",
    "# Custom aggregation function to calculate the average point for each group\n",
    "def calculate_average_point(group):\n",
    "    x_mean = group.x.mean()\n",
    "    y_mean = group.y.mean()\n",
    "    return Point(x_mean, y_mean)\n",
    "\n",
    "\n",
    "# Apply the custom aggregation function to calculate average points per group\n",
    "lines_to_update2 = lines_to_update.set_index(group_name)\n",
    "lines_to_update2['new_geometry'] = result_gdf.groupby(group_name)[geometry].apply(calculate_average_point)\n",
    "\n",
    "# 4.2 Among whom are updated remove every line the start and last point are the same\n",
    "# Get all the lines going to be deleted\n",
    "lines_to_delete = []\n",
    "\n",
    "\n",
    "def update_lines_to_delete(row):\n",
    "    # explode the lines names within each row list to separate rows\n",
    "    lines_to_update_tmep = row[index_right].explode()\n",
    "\n",
    "    # Identify rows with duplicate values\n",
    "    lines_to_delete.extend(lines_to_update_tmep[lines_to_update_tmep.duplicated()].tolist())\n",
    "\n",
    "\n",
    "lines_to_update2.groupby(level=group_name).apply(update_lines_to_delete)\n",
    "\n",
    "# remove lines their geometry not going to change\n",
    "lines_to_update3 = lines_to_update2[lines_to_update2[geometry] != lines_to_update2[new_geometry]]\n",
    "\n",
    "# 4.3 Change the point of each line with new point\n",
    "network_new = network[~network.index.isin(lines_to_delete)]\n",
    "\n",
    "\n",
    "def update_network_with_aggregated_point(group):\n",
    "    lines_in_group = group.explode(index_right)\n",
    "\n",
    "    def update_one_line(points_data):\n",
    "        if points_data.name not in lines_to_delete:\n",
    "            updated_line_geo = network_new.loc[points_data.name]\n",
    "            line_coords = updated_line_geo.geometry.coords\n",
    "            if Point(line_coords[0]) == points_data.geometry:\n",
    "                network_new.at[points_data.name, geometry] = LineString(\n",
    "                    [points_data[new_geometry]] + line_coords[1:])\n",
    "            elif Point(line_coords[-1]) == points_data.geometry:\n",
    "                network_new.at[points_data.name, geometry] = LineString(\n",
    "                    line_coords[:-1] + [points_data[new_geometry]])\n",
    "            else:\n",
    "                print(points_data)\n",
    "                print(lines_in_group)\n",
    "\n",
    "    lines_in_group.set_index(index_right).apply(update_one_line, axis=1)\n",
    "\n",
    "\n",
    "lines_to_update3.groupby(level=group_name).apply(update_network_with_aggregated_point)\n",
    "\n",
    "line_name = 'line_name'\n",
    "\n",
    "network_new.to_file(f'{data_folder}/network_new.shp')"
   ],
   "id": "initial_id",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "94edbde9d3854f8f",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
